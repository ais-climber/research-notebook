<TeXmacs|2.1.1>

<style|<tuple|letter|compact-list|termes-font>>

<\body>
  <\hide-preamble>
    \;

    <assign|signature|<macro|body|<surround|<vspace*|5fn><left-flush>||<signature*|<arg|body>>>>>

    <assign|closing|<macro|body|<surround|<left-flush>||<signature*|<arg|body>>>>>

    <assign|doc-misc|<macro|body|<doc-title-block|<arg|body>>>>

    <assign|doc-title|<macro|x|<\surround|<vspace*|0.5fn>|<vspace*|0.5fn>>
      <doc-title-block|<font-magnify|1.682|<doc-title-name|<arg|x>>>>
    </surround>>>

    <assign|doc-title-name|<macro|x|<arg|x>>>

    <assign|opening|<macro|body|<vspace|0.33fn><opening*|<arg|body>>>>

    <assign|bibliography-text|<macro|<localize|References>>>
  </hide-preamble>

  <center|<tabular|<tformat|<cwith|1|-1|2|2|cell-halign|c>|<cwith|1|-1|2|2|cell-valign|c>|<twith|table-width|1par>|<twith|table-hmode|exact>|<twith|table-bborder|0.075fn>|<cwith|1|1|2|2|cell-bsep|1fn>|<cwith|3|3|1|-1|cell-lsep|0fn>|<cwith|3|3|1|-1|cell-rsep|0fn>|<cwith|3|3|1|-1|cell-bsep|0fn>|<cwith|3|3|1|-1|cell-tsep|0fn>|<table|<row|<cell|>|<cell|<huge|Caleb
  Schultz Kisby>>|<cell|>>|<row|<cell|>|<cell|<tabular|<tformat|<table|<row|<cell|<with|font-series|bold|Email:>
  <hlink|cckisby@gmail.com|mailto:cckisby@iu.edu>>|<cell|<space|2em>>|<cell|<with|font-series|bold|Website:>
  <hlink|ais-climber.github.io|https://ais-climber.github.io/>>>>>>>|<cell|>>|<row|<cell|>|<cell|>|<cell|>>>>>>

  \;

  <with|font-series|bold|Position:> Postdoctoral Research Position in
  Human(e) AI, University of Amsterdam<vspace|1fn>

  <\opening>
    Dear members of the Human(e) AI Steering Board,
  </opening>

  <todo|Paragraph 1: Intro> I'm writing to apply for a Postdoc position
  through your Human(e) AI RPA, within the AI and Logic track. I am currently
  a PhD candidate in Computer Science at Indiana University (expected
  defense: April 2025).

  I primarily consider myself a logician, or a theoretical computer scientist
  in my home discipline. But as a logician I find myself in a unique
  position. Unlike most people trained in philosophical logic, I have
  experience doing traditional machine learning research, with the
  literature, and developing and experimenting on neural networks.
  <todo|Actively involved in the neuro-symbolic community, as well as the
  general AI community. Invited to present my work connecting logic and
  neural networks at the AAAI Conference on Artificial Intelligence and at
  the International Florida AI Research Society Conference.> Because of this
  experience, having my foot firmly in both doors, in my research I apply
  formal logics as a tool to develop safe, trustworthy, interpretable machine
  learning systems. My thesis work is on the theory of neuro-symbolic AI,
  where I use insights from logic to better understand and guide the behavior
  of neural networks as they learn over time. My long-term goal is to bring
  these ideas to bear on two of the most critical issues in artifical
  intelligence: neural network verification and the possibility of AI
  alignment. (I think I have to explain what AI alignment is, especially as
  the agent learns over time) I should also say concretely what it is I'm
  sitting on, a method for building a neural network that obeys constraints
  (in non-normal modal logic) about it's behavior
  <with|font-shape|italic|before and after> learning!

  <todo|Paragraph 2: Research> <todo|Emphasizing other things such as: has my
  research been funded by a grant (yes, it was pitched successfully to the US
  Dept of Defense); interdisciplinary nature of my work, and my experience
  working in inter-disciplinary teams (grant team, cogsci seminar, logic
  seminar, I've gotten very comfortable talking across fields with
  mathematicians, logicians, epistemologists, programming language theorists,
  cognitive scientists, and social scientists. I'm open to finding common
  ground as well between economicists, ethicists, and law researchers.)>

  <todo|Emphasize that I have experience with talking across fields in
  inter-disciplinary environments. Especially to linguists, philosophers,
  mathematicians, and cognitive scientists. I've participated in & given
  talks at logic seminar at IU, cognitive lunch & colloquium at IU. Also
  given talks at LiRA, participated in NeSy.>

  <todo|Paragraph 3: Collaboration with LIRa team> On a personal note, the
  direction and flavor of my research is in large part influenced by the work
  of the Amsterdam Dynamics Group at the ILLC. I was inspired by a number of
  their papers that demonstrate how dynamic logic can be used to model and
  characterize various types of belief revision and learning. Last January, I
  had the opportunity to meet Sonja Smets and Alexandru Baltag at the General
  Algebra, Logic & AI workshop held at Chapman University, where the three of
  us were invited speakers. They then invited me to speak on my work on
  neural network models and dynamic logic at the LIRa seminar.

  \;

  \ <todo|this is very clinical, I should say how I feel about them :)> I
  would be delighted to collaborate with the Dynamics team on\ 

  \;

  \;

  I have since met a number of folks through LIRa,\ 

  I would be delighted to continue this collaboration at with this group at
  UvA.

  \;

  Since then, I've been occasionally attending the seminar

  during my PhD I have found a lot of inspiration from the work done at\ 

  We discussed possible collaborations / at this workshop, we realized that
  my neural network / we realized that the framework I've been looking at for
  modelling neural network dynamics and the framework they have been looking
  at for social network dynamics are founded on the same ideas, and very
  likely the two can be integrated into a coherent / unified account of
  social networks

  \;

  <todo|Paragraph 4: Collaboration within Human(e) AI> <todo|definitely
  include a few sentences about research-based teaching opportunities with
  motivated students, or mentoring PhD students or undergrad> As I explain in
  more detail in my research proposal, <todo|actually, be very direct and to
  the point about an explicit direction for collaboration.> [make this a very
  brief description of my proposal, directions I'd like to take it in.] I'm
  excited to take this project to UvA and work with others on the Human(e) AI
  RPA\VI have two specific points of collaboration. First, I would like to
  collaborate with the [logic team, Lira, ILLC] to understand the power of
  neural network learning. Their work on logically analyzing updates and
  change in social networks is very closely related to my work analyzing
  updates and change in neural networks\Vthe two differ mainly in
  formalization and perspective (what do I mean by that?). The updates that
  they look at can offer a fresh perspective on neural networks, and
  vice-versa neural network updates can offer a fresh perspective on social
  dynamics (what do I mean by <with|font-shape|italic|that>?? Be specific!)
  Second, I would like to collaborate with law and ethics experts within
  [which team/subproject/whatever] in order to do construct neural networks
  that automatically obey <with|font-shape|italic|realistic ethical
  constraints>, regardless of what they learn or how the neural network
  changes over time.

  <todo|Paragraph 5: Conclusion>

  <\closing>
    Thank you for your time and consideration,
  </closing>

  <\signature>
    Caleb Schultz Kisby
  </signature>
</body>

<\initial>
  <\collection>
    <associate|bg-color|#f9f5d7>
    <associate|font-base-size|12>
    <associate|item-vsep|<macro|0.3fn>>
    <associate|math-font|math-termes>
    <associate|page-bot|1in>
    <associate|page-even|1in>
    <associate|page-even-footer|<htab|5mm>>
    <associate|page-even-header|>
    <associate|page-height|auto>
    <associate|page-medium|paper>
    <associate|page-odd|1in>
    <associate|page-odd-footer|<htab|5mm>>
    <associate|page-odd-header|>
    <associate|page-right|1in>
    <associate|page-screen-margin|false>
    <associate|page-top|1in>
    <associate|page-type|letter>
    <associate|page-width|auto>
    <associate|par-par-sep|0.5fn>
    <associate|par-sep|0.3fn>
  </collection>
</initial>

<\references>
  <\collection>
    <associate|auto-1|<tuple|?|3>>
    <associate|bib-baltag2019dynamic|<tuple|1|3>>
    <associate|bib-baltag2019right|<tuple|2|3>>
    <associate|bib-leitgeb2018neural|<tuple|3|3>>
  </collection>
</references>

<\auxiliary>
  <\collection>
    <\associate|toc>
      <vspace*|1fn><with|font-series|<quote|bold>|math-font-series|<quote|bold>|References>
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-1><vspace|0.5fn>
    </associate>
  </collection>
</auxiliary>